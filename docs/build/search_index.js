var documenterSearchIndex = {"docs":
[{"location":"#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"AskAI.jl, as its name suggests, is a straightforward tool for querying Large Language Models.  Currently supporting only Google's Gemini model due to its free, though rate-limited, API, it's designed to be simple and direct: send prompts and questions to Gemini, and optionally execute the included code within a sandboxed \"playground\" to avoid affecting the main scope.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"The main macro, @ai, retrieves results from a large language model (current the Gemini, more model supported soon), while @AI executes the code within the \"playground\" scope and displays the output(or any errors.)","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"a REPL mode was also support. Press } to enter and backspace to exit","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"(Image: AskAI)","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"note: Note\nas most of the AI tool, it needs the api key, for the Gemini key you can apply from Google Gemini. and the set it in the ENV[\"AI_API_KEY\"] or use AskAI.setapi() to replace new key. please also add a module called playground: module playground end in your main scope for the code execute. ","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"note: Note\nA convenient way is to put below code in your Julia startup.jl configuration file.ENV[\"AI_API_KEY\"] = \"your_key_for_Google_Gemini\"\nmodule playground end\nusing AskAIthen you can use the AskAI in every session by default","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"it starts as my persional AI tool in julia REP and only support the Gemini model currently. have fun with it and I welcome your suggestions and input for AskAI.jl!!!","category":"page"},{"location":"#quickly-example","page":"Overview","title":"quickly example","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Here's an example of using AskAI to generate scatter and histogram plots and perform basic statistical calculations.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"@AI \"tell me the current date, use the pacakge when in need\"\n@AI \"create a new project in /tmp, name it as demo + date, activate it\"\n@AI \"load my data as df, the data file is in /tmp/celldata.csv\"\n@AI \"tell me the data size\"\n@AI \"does the data contain columns named geneX and  geneY??\"\n@AI \"install the package to support figure display in the terminal\"\n@AI \"plot a scatter plot of geneX and geneY, I want the geneX on axis Y\"\n@AI \"please also label the axis\"\n@AI \"calculate the correlation of geneX and geneY\"\n@AI \"keep only 3 digits\"\n@AI \"generate a histogram to show the distribution of geneX \"\n@AI \"do the same to geneY\"\n@AI \"fit a linear model to predict value of geneY from geneX,using GLM\"\n@AI \"give me the coef of geneX in this model,keep 5 digits\"","category":"page"},{"location":"#Output-Results-are-here","page":"Overview","title":"Output Results are here","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"details: Details\n(Image: result1) (Image: result2) (Image: result3)","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"note: Note\nsome time you may get the wrong result from the LLM, LLM results aren't always perfect, so please double-check. You can use @ai instead of @AI for code checks. then use exe() to perform the code. Often the case I met is the necessary packages aren't installed.@ai \"tell me the current date,install the package if it needs\"\nAskAI.exe(ans)","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"to review the conversation history","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"AskAI.Brain.history[\"ask\"] \nAskAI.Brain.history[\"ans\"] \n\n# review the last response \nAskAI.Brain.history[\"ans\"][end] |> AskAI.MD","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"you can also try the stream mode under terminal","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"AskAI.Brain.stream = true\n@ai \"why the sky is blue\"","category":"page"},{"location":"#function-and-macro","page":"Overview","title":"function and macro","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Modules = [AskAI]\nPages   = [\"AskAI.jl\", \"brain.jl\"]","category":"page"},{"location":"#AskAI.exe-Tuple{Any}","page":"Overview","title":"AskAI.exe","text":"execute the string as code\n\n\"1 + 1\" |> AskAI.exe\n\n(@ai \"1 + 1\") |> AskAI.exe\n\n\n\n\n\n","category":"method"},{"location":"#AskAI.reset-Tuple{}","page":"Overview","title":"AskAI.reset","text":"Reset the AskAI, it will remove the conversation history, memory, prompt... and everything as default defined\n\nAskAI.reset()\n\n\n\n\n\n","category":"method"},{"location":"#AskAI.setapi-Tuple{AbstractString}","page":"Overview","title":"AskAI.setapi","text":"set the API_KEY\n\nsetapi(\"1234567890abcdef1234567890abcdef\")\n\n\n\n\n\n","category":"method"},{"location":"#AskAI.@AI-Tuple{Any}","page":"Overview","title":"AskAI.@AI","text":"similar to @ai,\n\nsend the question to AI but @AI perform the code directly and only return the result, or error :(\n\nthe conversation history will stored in the AskAI.Brain.history\n\nexample:\n\n@AI \"tell me the current time, used the package you need\"\n\n\n\n\n\n","category":"macro"},{"location":"#AskAI.@ai-Tuple{Any}","page":"Overview","title":"AskAI.@ai","text":"get the answer from the AI\n\nexample\n\n@ai \"fit a linear model\"\n# or you can concatenate your question\n@ai \"fit a\" + \"linear model\"\n\n\n\n\n\n","category":"macro"},{"location":"#AskAI.checkMemory!","page":"Overview","title":"AskAI.checkMemory!","text":"optimalize the memory text, when the memory words length exceeds 3000 words,  summary it into 300 words\n\n\n\n\n\n","category":"function"},{"location":"#AskAI.showStreamStringFromChannel-Tuple{Channel}","page":"Overview","title":"AskAI.showStreamStringFromChannel","text":"for stream mode, displays a streaming response from the channel, updating the display in terminal with each chunk of text received.\n\n\n\n\n\n","category":"method"},{"location":"#AskAI.streamToMemory-Tuple{AskAI.AIBrain, Channel}","page":"Overview","title":"AskAI.streamToMemory","text":"for stream mode, take string from the channel, convert to markdown, and save as memory context\n\n\n\n\n\n","category":"method"}]
}
